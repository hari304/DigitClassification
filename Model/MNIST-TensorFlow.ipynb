{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.python.tools import optimize_for_inference_lib\n",
    "from tensorflow.python.platform import gfile\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_STEP = 2000\n",
    "BATCH_SIZE = 100\n",
    "tf.reset_default_graph()\n",
    "\n",
    "def model_input(input_node_name,keep_prob_node_name):\n",
    "    x = tf.placeholder(tf.float32,shape=[None,28,28,1],name=input_node_name)\n",
    "    keep_prob = tf.placeholder(tf.float32,name=keep_prob_node_name)\n",
    "    y_ = tf.placeholder(tf.float32,shape=[None,10])\n",
    "    return x,keep_prob,y_\n",
    "\n",
    "def build_model(x,keep_prob,y_,output_node_name):\n",
    "    x_image = tf.reshape(x,[-1,28,28,1])\n",
    "    \n",
    "    #conv1 = 28X28X32\n",
    "    conv1 = tf.layers.conv2d(\n",
    "    inputs=x_image,\n",
    "    filters=32,\n",
    "    kernel_size=[5,5],\n",
    "    padding='same',\n",
    "    activation=tf.nn.relu) \n",
    "    #pad1 = 14X14X32\n",
    "    pad1 = tf.layers.max_pooling2d(inputs=conv1,pool_size=[2,2],strides=2)\n",
    "    \n",
    "    #conv2 = 14X14X64\n",
    "    conv2 = tf.layers.conv2d(\n",
    "    inputs=pad1,\n",
    "    filters=64,\n",
    "    kernel_size=[5,5],\n",
    "    padding='same',\n",
    "    activation=tf.nn.relu)\n",
    "    #pad2 = 7X7X64\n",
    "    pad2 = tf.layers.max_pooling2d(inputs=conv2,pool_size=[2,2],strides=2)\n",
    "    \n",
    "    pad2flat = tf.reshape(pad2,[-1,7*7*64])\n",
    "    \n",
    "    dense = tf.layers.dense(inputs=pad2flat,units=1024,activation=tf.nn.relu)\n",
    "    \n",
    "    dropout = tf.layers.dropout(inputs=dense,rate=keep_prob)\n",
    "    \n",
    "    logits = tf.layers.dense(inputs=dropout,units=10)\n",
    "    outputs = tf.nn.softmax(logits,name=output_node_name)\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_,logits=logits))\n",
    "    \n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(outputs,1),tf.argmax(y_,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    \n",
    "    tf.summary.scalar(\"loss\", loss)\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)\n",
    "    merged_summary_op = tf.summary.merge_all()\n",
    "    \n",
    "    return train_step,loss,accuracy,merged_summary_op\n",
    "\n",
    "def train(x,keep_prob,y_,train_step,loss,accuracy,merged_summary_op,saver):\n",
    "    print('training Started.....')\n",
    "    mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "    \n",
    "    init_op = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "        tf.train.write_graph(sess.graph_def,'model','mnist_cnn.pbtxt',True)\n",
    "        for step in range(NUM_STEP):\n",
    "            batch = mnist.train.next_batch(BATCH_SIZE)\n",
    "            if step%100 == 0:\n",
    "                train_accuracy = accuracy.eval(feed_dict={x:np.asarray(batch[0].reshape(-1,28,28,1),dtype=np.float32)\n",
    "                                                          ,y_:batch[1],keep_prob:1.0})\n",
    "                print('step ',step,' training accuracy: ',train_accuracy)\n",
    "            _,summary = sess.run([train_step,merged_summary_op],\n",
    "                                feed_dict={x:np.asarray(batch[0].reshape(-1,28,28,1),dtype=np.float32)\n",
    "                                           ,y_:batch[1],keep_prob:0.5})\n",
    "            \n",
    "        saver.save(sess,'/home/hari304/MNIST/model/mnist_cnn.chkp')\n",
    "        test_accuracy = accuracy.eval(feed_dict={x:mnist.test.images.reshape(-1,28,28,1),y_:mnist.test.labels,keep_prob:1.0})\n",
    "    print(' test accuracy: ',test_accuracy)\n",
    "    print('training finished!')\n",
    "    \n",
    "def gen_tflite_graph(input_node_names,output_node_name):\n",
    "    freeze_graph.freeze_graph('/home/hari304/MNIST/model/mnist_cnn.pbtxt', None, False,\n",
    "        '/home/hari304/MNIST/model/mnist_cnn.chkp', output_node_name, \"save/restore_all\",\n",
    "        \"save/Const:0\", '/home/hari304/MNIST/model/mnist_cnn.pb', True, \"\")\n",
    "    \n",
    "    input_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.Open('/home/hari304/MNIST/model/mnist_cnn.pb', \"rb\") as f:\n",
    "        input_graph_def.ParseFromString(f.read())\n",
    "        \n",
    "    output_graph_def = optimize_for_inference_lib.optimize_for_inference(\n",
    "            input_graph_def, [input_node_names[0]], [output_node_name],\n",
    "            tf.float32.as_datatype_enum)\n",
    "\n",
    "    with tf.gfile.FastGFile('/home/hari304/MNIST/model/mnist_cnn.pb', \"wb\") as f:\n",
    "        f.write(output_graph_def.SerializeToString())\n",
    "        \n",
    "    converter = tf.contrib.lite.TFLiteConverter.from_frozen_graph('/home/hari304/MNIST/model/mnist_cnn.pb',\n",
    "                                                                [input_node_names[0]],\n",
    "                                                                [output_node_name],input_shapes={'input':[1,28,28,1]})\n",
    "    tflite_model = converter.convert()\n",
    "    open('/home/hari304/MNIST/model/mnist_cnn.tflite','wb').write(tflite_model)\n",
    "    print('TFLITE graph saved!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Started.....\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "step  0  training accuracy:  0.1\n",
      "step  100  training accuracy:  0.92\n",
      "step  200  training accuracy:  0.89\n",
      "step  300  training accuracy:  0.92\n",
      "step  400  training accuracy:  0.97\n",
      "step  500  training accuracy:  0.95\n",
      "step  600  training accuracy:  0.97\n",
      "step  700  training accuracy:  0.97\n",
      "step  800  training accuracy:  0.96\n",
      "step  900  training accuracy:  0.98\n",
      "step  1000  training accuracy:  0.98\n",
      "step  1100  training accuracy:  0.98\n",
      "step  1200  training accuracy:  0.99\n",
      "step  1300  training accuracy:  0.97\n",
      "step  1400  training accuracy:  0.97\n",
      "step  1500  training accuracy:  0.98\n",
      "step  1600  training accuracy:  0.97\n",
      "step  1700  training accuracy:  1.0\n",
      "step  1800  training accuracy:  0.98\n",
      "step  1900  training accuracy:  0.99\n",
      " test accuracy:  0.9866\n",
      "training finished!\n",
      "INFO:tensorflow:Restoring parameters from /home/hari304/MNIST/model/mnist_cnn.chkp\n",
      "INFO:tensorflow:Froze 8 variables.\n",
      "INFO:tensorflow:Converted 8 variables to const ops.\n",
      "TFLITE graph saved!\n"
     ]
    }
   ],
   "source": [
    "input_node_name = 'input'\n",
    "keep_prob_node_name = 'keep_prob'\n",
    "output_node_name = 'output'\n",
    "x,keep_prob,y_ = model_input(input_node_name,keep_prob_node_name)\n",
    "train_step,loss,accuracy,merged_summary_op = build_model(x,keep_prob,y_,output_node_name)\n",
    "saver = tf.train.Saver()\n",
    "train(x,keep_prob,y_,train_step,loss,accuracy,merged_summary_op,saver)\n",
    "gen_tflite_graph([input_node_name,keep_prob_node_name], output_node_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
